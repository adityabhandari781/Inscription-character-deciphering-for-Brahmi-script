{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10c2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import json\n",
    "\n",
    "img = Image.open(\"/mnt/windows/Users/adity/Downloads/output/100_engraved.png\").convert(\"RGB\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "with open(\"/mnt/windows/Users/adity/Downloads/output/100.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for item in data:\n",
    "    x1, y1, x2, y2 = item[\"bbox\"]\n",
    "    draw.rectangle(\n",
    "        [x1, y1, x2, y2],\n",
    "        outline=\"red\",\n",
    "        width=2\n",
    "    )\n",
    "\n",
    "img.save(\"boxed.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"0_engraved.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "denoise = cv2.medianBlur(gray, 3)\n",
    "\n",
    "# show denoise:\n",
    "cv2.imshow(\"denoise\", denoise)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d1778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, thresh = cv2.threshold(\n",
    "    denoise, 0, 255,\n",
    "    cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    ")\n",
    "cv2.imshow(\"thresh_otsu\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83448fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "clean = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow(\"clean\", clean)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c0f331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
    "clean_ = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow(\"clean_\", clean_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# saving\n",
    "cv2.imwrite(\"0_clean.png\", clean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "710dc854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the above pipeline for each img in \"/mnt/windows/Users/adity/Downloads/output/\". each image is titled \"X_engraved.png\" where X is a number from 0 to 999, and saving as \"X_clean.png\" in the same directory.\n",
    "\n",
    "import os\n",
    "for i in range(1000):\n",
    "    img_path = f\"/mnt/windows/Users/adity/Downloads/output/{i}_engraved.png\"\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    denoise = cv2.medianBlur(gray, 3)\n",
    "    _, thresh = cv2.threshold(\n",
    "        denoise, 0, 255,\n",
    "        cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    clean = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
    "    clean_ = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel)\n",
    "    save_path = f\"/mnt/windows/Users/adity/Downloads/output1/{i}_clean.png\"\n",
    "    cv2.imwrite(save_path, clean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e1d9fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning /mnt/windows/Users/adity/Downloads/output_clean/...\n",
      "Found 1000 valid image-JSON pairs.\n",
      "Building class vocabulary...\n",
      "Found 0 unique characters.\n",
      "Converting and moving files...\n",
      "Data preparation complete. 'brahmi_config.yaml' created.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "RAW_DATA_DIR = \"/mnt/windows/Users/adity/Downloads/output_clean/\"\n",
    "OUTPUT_DIR = \"datasets/brahmi_ocr\"\n",
    "\n",
    "def convert_bbox_to_yolo(bbox, img_width, img_height):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    \n",
    "    dw = 1.0 / img_width\n",
    "    dh = 1.0 / img_height\n",
    "    \n",
    "    w = xmax - xmin\n",
    "    h = ymax - ymin\n",
    "    x_center = xmin + w / 2.0\n",
    "    y_center = ymin + h / 2.0\n",
    "    \n",
    "    x_center *= dw\n",
    "    w *= dw\n",
    "    y_center *= dh\n",
    "    h *= dh\n",
    "    \n",
    "    return x_center, y_center, w, h\n",
    "\n",
    "def main():\n",
    "    # 1. Identify all valid pairs\n",
    "    print(f\"Scanning {RAW_DATA_DIR}...\")\n",
    "    valid_pairs = [] \n",
    "    \n",
    "    for i in range(1000):\n",
    "        json_filename = f\"{i}.json\"\n",
    "        img_filename = f\"{i}_clean.png\"\n",
    "        \n",
    "        json_path = os.path.join(RAW_DATA_DIR, json_filename)\n",
    "        img_path = os.path.join(RAW_DATA_DIR, img_filename)\n",
    "        \n",
    "        if os.path.exists(json_path) and os.path.exists(img_path):\n",
    "            valid_pairs.append((json_path, img_path, str(i)))\n",
    "    \n",
    "    print(f\"Found {len(valid_pairs)} valid image-JSON pairs.\")\n",
    "\n",
    "    if len(valid_pairs) == 0:\n",
    "        print(\"Error: No data found. Check your paths.\")\n",
    "        return\n",
    "\n",
    "    # 2. Build Class Vocabulary\n",
    "    print(\"Building class vocabulary...\")\n",
    "    unique_chars = set()\n",
    "    \n",
    "    for json_path, _, _ in valid_pairs:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                for item in data:\n",
    "                    # FIX: Check if 'char' exists before accessing it\n",
    "                    if 'char' in item:\n",
    "                        unique_chars.add(item['char'])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping corrupted JSON: {json_path}\")\n",
    "\n",
    "    char_to_id = {char: idx for idx, char in enumerate(sorted(list(unique_chars)))}\n",
    "    id_to_char = {idx: char for char, idx in char_to_id.items()}\n",
    "    \n",
    "    print(f\"Found {len(char_to_id)} unique characters.\")\n",
    "    \n",
    "    # Save mapping\n",
    "    with open(\"class_mapping.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(char_to_id, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 3. Prepare Directories\n",
    "    for split in ['train', 'val']:\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, 'images', split), exist_ok=True)\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, 'labels', split), exist_ok=True)\n",
    "\n",
    "    # 4. Split Data\n",
    "    train_pairs, val_pairs = train_test_split(valid_pairs, test_size=0.2, random_state=42)\n",
    "    splits = {'train': train_pairs, 'val': val_pairs}\n",
    "\n",
    "    # 5. Process Files\n",
    "    print(\"Converting and moving files...\")\n",
    "    for split, pairs in splits.items():\n",
    "        for json_path, img_path, base_id in pairs:\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None: continue\n",
    "            height, width = img.shape[:2]\n",
    "\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                annotations = json.load(f)\n",
    "\n",
    "            yolo_lines = []\n",
    "            for ann in annotations:\n",
    "                # FIX: Skip entries without 'char'\n",
    "                if 'char' not in ann:\n",
    "                    continue\n",
    "                \n",
    "                char = ann['char']\n",
    "                \n",
    "                # Verify char is in our list (it should be)\n",
    "                if char not in char_to_id: \n",
    "                    continue\n",
    "                \n",
    "                cls_id = char_to_id[char]\n",
    "                \n",
    "                # Check if 'bbox' exists too\n",
    "                if 'bbox' not in ann:\n",
    "                    continue\n",
    "                    \n",
    "                bbox = ann['bbox'] \n",
    "                xc, yc, w, h = convert_bbox_to_yolo(bbox, width, height)\n",
    "                \n",
    "                if w > 0 and h > 0:\n",
    "                    yolo_lines.append(f\"{cls_id} {xc} {yc} {w} {h}\")\n",
    "\n",
    "            # Only write files if we found valid lines\n",
    "            if len(yolo_lines) > 0:\n",
    "                label_out_path = os.path.join(OUTPUT_DIR, 'labels', split, base_id + \".txt\")\n",
    "                with open(label_out_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"\\n\".join(yolo_lines))\n",
    "\n",
    "                out_img_name = base_id + \".png\"\n",
    "                shutil.copy(img_path, os.path.join(OUTPUT_DIR, 'images', split, out_img_name))\n",
    "\n",
    "    # 6. Create YAML Config\n",
    "    yaml_content = f\"\"\"\n",
    "path: {os.path.abspath(OUTPUT_DIR)}\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: {len(char_to_id)}\n",
    "names: {list(id_to_char.values())}\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(\"brahmi_config.yaml\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(yaml_content)\n",
    "        \n",
    "    print(\"Data preparation complete. 'brahmi_config.yaml' created.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
